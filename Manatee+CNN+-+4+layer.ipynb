{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from skimage import data,io,filters\n",
    "from os import listdir,system\n",
    "import shutil\n",
    "#from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "import numpy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'U0400'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_dataset_array = numpy.loadtxt('Experiment2/train_labels_mini_final.txt', dtype=str)\n",
    "\n",
    "train_labels_dataset_array[1]\n",
    "#Total images:1354(without augmenatation)\n",
    "#After augmenatation: 9478\n",
    "#unique manatees: 1345\n",
    "#print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606592, 128)\n",
      "(9478, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "# Read the array from dis\n",
    "train_dataset_array = numpy.loadtxt('Experiment2/train_mini_final.txt')\n",
    "\n",
    "# Note that this returned a 2D array!\n",
    "print(train_dataset_array.shape)\n",
    "\n",
    "# However, going back to 3D is easy if we know the \n",
    "# original shape of the array\n",
    "train_dataset_array = train_dataset_array.reshape((9478,64,128))\n",
    "\n",
    "print(train_dataset_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_labels_one_hot = numpy.zeros((9478,1354))\n",
    "for i in range(1354):\n",
    "    #try using the logic to keep i value as same while reading from labels file\n",
    "    for j in range(7): #7 is no. of augments\n",
    "        train_labels_one_hot[i*7+j][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5184, 128)\n",
      "(81, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "# Read the array from disk\n",
    "test_dataset_array = numpy.loadtxt('Experiment2/test_mini_final.txt')\n",
    "\n",
    "# Note that this returned a 2D array!\n",
    "print(test_dataset_array.shape)\n",
    "\n",
    "# However, going back to 3D is easy if we know the \n",
    "# original shape of the array\n",
    "test_dataset_array = test_dataset_array.reshape((81,64,128))\n",
    "\n",
    "print(test_dataset_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81,)\n"
     ]
    }
   ],
   "source": [
    "# Read the array from disk\n",
    "test_labels_dataset_array = numpy.loadtxt('Experiment2/test_labels_mini_final.txt', dtype=str)\n",
    "\n",
    "print(test_labels_dataset_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_labels_one_hot = numpy.zeros((81,1354))\n",
    "for i in range(81):\n",
    "    temp_arr = numpy.where(train_labels_dataset_array == test_labels_dataset_array[i])\n",
    "    #print(temp_arr)\n",
    "    try:\n",
    "        idx = (temp_arr[0][0]//7)\n",
    "    except:\n",
    "        pass\n",
    "    test_labels_one_hot[i][idx] = 1\n",
    "#print(test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_dataset_array = train_dataset_array.reshape(9478,8192)\n",
    "test_dataset_array = test_dataset_array.reshape(81,8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 8192])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1354])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        n_out:       integer, depth of input maps\n",
    "        phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('bn'):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,64,128,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "phase_train = tf.placeholder(tf.bool, name='phase_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "\n",
    "conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "conv1_bn = batch_norm(conv1, 32, phase_train)\n",
    "h_conv1 = tf.nn.relu(conv1_bn)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "\n",
    "conv2 = conv2d(h_pool1, W_conv2) + b_conv2\n",
    "conv2_bn = batch_norm(conv2, 64,  phase_train)\n",
    "h_conv2 = tf.nn.relu(conv2_bn)\n",
    "\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv3 = weight_variable([3, 3, 64, 128])\n",
    "b_conv3 = bias_variable([128])\n",
    "\n",
    "\n",
    "conv3 = conv2d(h_pool2, W_conv3) + b_conv3\n",
    "conv3_bn = batch_norm(conv3, 128,  phase_train)\n",
    "h_conv3 = tf.nn.relu(conv3_bn)\n",
    "\n",
    "W_conv3_2 = weight_variable([3, 3, 128, 128])\n",
    "b_conv3_2 = bias_variable([128])\n",
    "\n",
    "\n",
    "conv3_2 = conv2d(h_conv3, W_conv3_2) + b_conv3_2\n",
    "conv3_2_bn = batch_norm(conv3_2, 128,  phase_train)\n",
    "h_conv3_2 = tf.nn.relu(conv3_2_bn)\n",
    "\n",
    "h_pool3 = max_pool_2x2(h_conv3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([8 * 16 * 128, 4096])\n",
    "b_fc1 = bias_variable([4096])\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 8 * 16 * 128])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([4096, 1354])\n",
    "b_fc2 = bias_variable([1354])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0\n",
      "step 0, top 1 1\n",
      "step 0, top 5 1\n",
      "step 0, top 10 2\n",
      "step 0, top 20 2\n",
      "step 1, training accuracy 0.0295567\n",
      "step 2, training accuracy 0\n",
      "step 3, training accuracy 0\n",
      "step 4, training accuracy 0\n",
      "step 5, training accuracy 0\n",
      "step 6, training accuracy 0\n",
      "step 7, training accuracy 0\n",
      "step 8, training accuracy 0\n",
      "step 9, training accuracy 0\n",
      "step 10, training accuracy 0\n",
      "step 11, training accuracy 0\n",
      "step 12, training accuracy 0\n",
      "step 13, training accuracy 0\n",
      "step 14, training accuracy 0\n",
      "step 15, training accuracy 0\n",
      "step 16, training accuracy 0\n",
      "step 17, training accuracy 0\n",
      "step 18, training accuracy 0\n",
      "step 19, training accuracy 0\n",
      "step 20, training accuracy 0\n",
      "step 21, training accuracy 0\n",
      "step 22, training accuracy 0\n",
      "step 23, training accuracy 0\n",
      "step 24, training accuracy 0\n",
      "step 25, training accuracy 0\n",
      "step 26, training accuracy 0\n",
      "step 27, training accuracy 0\n",
      "step 28, training accuracy 0\n",
      "step 29, training accuracy 0\n",
      "step 30, training accuracy 0\n",
      "step 31, training accuracy 0\n",
      "step 32, training accuracy 0\n",
      "step 33, training accuracy 0\n",
      "step 34, training accuracy 0\n",
      "step 35, training accuracy 0\n",
      "step 36, training accuracy 0\n",
      "step 37, training accuracy 0\n",
      "step 38, training accuracy 0\n",
      "step 39, training accuracy 0\n",
      "step 40, training accuracy 0\n",
      "step 41, training accuracy 0\n",
      "step 42, training accuracy 0\n",
      "step 43, training accuracy 0\n",
      "step 44, training accuracy 0\n",
      "step 45, training accuracy 0\n",
      "step 46, training accuracy 0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv,labels= y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={phase_train:True})\n",
    "top_1_list = []\n",
    "top_5_list = []\n",
    "top_10_list = []\n",
    "top_20_list = []\n",
    "val = 1\n",
    "for i in range(15800):\n",
    "  batch_image = train_dataset_array[(val-1)*203:val*203,:]\n",
    "  batch_label = train_labels_one_hot[(val-1)*203:val*203,:]  \n",
    "   #batch = mnist.train.next_batch(50) \n",
    "  val=val+1;  \n",
    "  if val > 79:\n",
    "    val = 1\n",
    "  if i%1 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch_image, y_: batch_label, keep_prob: 1.0,  phase_train: False})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  if i%79==0:\n",
    "    #test_accuracy = accuracy.eval(feed_dict={\n",
    "        #x:test_dataset_array, y_: test_labels_one_hot, keep_prob: 1.0,  phase_train: False})\n",
    "    #print(\"step %d, test accuracy %g\"%(i, test_accuracy))  \n",
    "    labels = tf.argmax(test_labels_one_hot, 1)\n",
    "    \n",
    "    top_1 = tf.nn.in_top_k(y_conv, labels, 1)\n",
    "    predictions_1 = sess.run(top_1, feed_dict={ x:test_dataset_array, y_: test_labels_one_hot, keep_prob: 1.0,  phase_train: False})\n",
    "    top_1_val = numpy.sum(predictions_1)\n",
    "    print(\"step %d, top 1 %g\"%(i, top_1_val))\n",
    "    top_1_list.append(top_1_val)\n",
    "    \n",
    "    top_5 = tf.nn.in_top_k(y_conv, labels, 5)\n",
    "    predictions_5 = sess.run(top_5, feed_dict={ x:test_dataset_array, y_: test_labels_one_hot, keep_prob: 1.0,  phase_train: False})\n",
    "    top_5_val = numpy.sum(predictions_5)\n",
    "    print(\"step %d, top 5 %g\"%(i, top_5_val))\n",
    "    top_5_list.append(top_5_val)\n",
    "    \n",
    "    top_10 = tf.nn.in_top_k(y_conv, labels, 10)\n",
    "    predictions_10 = sess.run(top_10, feed_dict={ x:test_dataset_array, y_: test_labels_one_hot, keep_prob: 1.0,  phase_train: False})\n",
    "    top_10_val = numpy.sum(predictions_10)\n",
    "    print(\"step %d, top 10 %g\"%(i, top_10_val))\n",
    "    top_10_list.append(top_10_val)\n",
    "    \n",
    "    top_20 = tf.nn.in_top_k(y_conv, labels, 20)\n",
    "    predictions_20 = sess.run(top_20, feed_dict={ x:test_dataset_array, y_: test_labels_one_hot, keep_prob: 1.0,  phase_train: False})\n",
    "    top_20_val = numpy.sum(predictions_20)\n",
    "    print(\"step %d, top 20 %g\"%(i, top_20_val))\n",
    "    top_20_list.append(top_20_val)\n",
    "\n",
    "    saver.save(sess, 'model-4_2.ckpt')\n",
    "  train_step.run(feed_dict={x: batch_image, y_:batch_label, keep_prob: 0.5, phase_train: True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 2, 3, 3, 4, 4, 5, 5, 5, 3, 4, 4, 4, 5, 4, 8, 6, 7, 3, 2, 5, 7, 4, 6, 4, 7, 5, 10, 11, 12, 6, 9, 11, 8, 10, 10, 10, 11, 9, 11, 9, 12, 9, 11, 9, 12, 11, 13, 12, 14, 14, 12, 14, 15, 16, 15, 14, 14, 15, 17, 18, 13, 19, 19, 22, 21, 18, 17, 18, 17, 16, 21, 22, 24, 25, 21, 22, 21, 20, 21, 23, 22, 24, 20, 23, 23, 20, 26, 22, 24, 27, 28, 28, 28, 30, 31, 26, 31, 30, 29, 23, 30, 28, 27, 31, 25, 31, 30, 30, 29, 28, 31, 33, 35, 29, 35, 30, 32, 30, 32, 33, 32, 29, 32, 33, 30, 33, 32, 32, 28, 34, 33, 30, 33, 31, 29, 30, 31, 37, 33, 39, 34, 31, 33, 31, 33, 30, 34, 31, 32, 30, 35, 34, 29, 33, 31, 29, 31, 34, 37, 36, 38, 35, 32, 36, 33, 34, 34, 32, 35, 31, 34, 26, 29, 33, 37, 30, 36, 31, 33, 34, 29, 33, 34, 29, 33, 32, 37, 36, 33, 37, 35, 34, 40, 38, 34, 40, 33]\n"
     ]
    }
   ],
   "source": [
    "print(top_20_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
